{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"load_data_utkface.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"eF-bDXurGhsW"},"source":["from scipy.io import loadmat\n","from datetime import datetime\n","import os\n","import numpy as np\n","import numpy as np\n","import cv2\n","import argparse\n","from tqdm import tqdm\n","from pathlib import Path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qx-Tn09c4b8z"},"source":["### set parameters"]},{"cell_type":"code","metadata":{"id":"wFHvGki8Ghsm"},"source":["IMAGE_SIZE = 56\n","BATCH_SIZE = 256\n","WEIGHT_INIT = 0.08\n","NUM_GENDER_CLASSES = 2\n","input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n","min_score = 1.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UUoROgAMGhsn"},"source":["### create 3 classes"]},{"cell_type":"code","metadata":{"id":"ywSda_C9Ghso"},"source":["def create_3utk_data():\n","    img_dir = Path('./UTKFace/')\n","    img_size = IMAGE_SIZE\n","    num1_26 = 0\n","    num27_52 = 0\n","    num53_80 = 0\n","    male = 0\n","    female = 0\n","    White=0\n","    Black=0\n","    Asian=0\n","    Indian=0\n","    Others=0\n","    \n","    data = []\n","    for img_path in img_dir.glob('*.jpg'):\n","        name = img_path.name    # [age]_[gender]_[race]_[date&time].jpg\n","        age, gender,race = name.split('_')[:3]\n","        img = cv2.imread(str(img_path))\n","        \n","        age = int(age)\n","        if age >= 81:\n","            continue\n","\n","        if 1 <= age <= 26:\n","            num1_26 += 1\n","            label_age = 0\n","        elif 27 <= age <= 52:\n","            num27_52 += 1\n","            label_age = 1\n","        else:\n","            num53_80 += 1\n","            label_age = 2\n","\n","        label_gender = int(gender)\n","        if label_gender == 3:\n","            label_gender = 1\n","        if label_gender == 0:\n","            male += 1\n","        else:\n","            female += 1\n","\n","        label_gender = int(gender)\n","        if label_gender == 3:\n","            label_gender = 1\n","            \n","        label_race=int(race)\n","        if label_race==0:\n","            White=White+1\n","        if label_race==1:\n","            Black+=1\n","        if label_race==2:\n","            Asian+=1\n","        if label_race==3:\n","            Indian+=1\n","        if label_race==4:\n","            Others+=1\n","                 \n","        img = cv2.resize(img, (img_size, img_size), cv2.INTER_AREA)\n","        data.append((img, label_age, label_gender,label_race))\n","\n","    print('Number of data')\n","    print('1-26: ', num1_26)\n","    print('27-52: ', num27_52)\n","    print('53-80: ', num53_80)\n","    print('male: ', male)\n","    print('female: ', female)\n","    print('White: ', White)\n","    print('Black: ', Black)\n","    print('Asian: ', Asian)\n","    print('Indian: ', Indian)\n","    print('Others: ', Others)\n","    \n","    with open('data_3_ukt.npy','wb') as f:\n","        np.save(f, data)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSEuoMJxGhsp","outputId":"a51e4e0f-1313-4179-955b-44c9b0610362"},"source":["create_3utk_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of data\n","1-26:  9834\n","27-52:  9635\n","53-80:  3696\n","male:  12208\n","female:  10957\n","White:  9698\n","Black:  4478\n","Asian:  3348\n","Indian:  3952\n","Others:  1689\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9UDQYcLCGhsq"},"source":["### create 5 classes"]},{"cell_type":"code","metadata":{"id":"HPLKoZPTGhsr"},"source":["def create_5utk_data():\n","    img_dir = Path('./UTKFace/')\n","    img_size = IMAGE_SIZE\n","    num1_13 = 0\n","    num14_23 = 0\n","    num24_39 = 0\n","    num40_55 = 0\n","    num56_80 = 0\n","    male = 0\n","    female = 0\n","    White=0\n","    Black=0\n","    Asian=0\n","    Indian=0\n","    Others=0\n","    \n","    data = []\n","    for img_path in img_dir.glob('*.jpg'):\n","        name = img_path.name    # [age]_[gender]_[race]_[date&time].jpg\n","        age, gender,race = name.split('_')[:3]\n","        img = cv2.imread(str(img_path))\n","        \n","        age = int(age)\n","        if age >= 81:\n","            continue\n","\n","        if 1 <= age <= 11:\n","            num1_13 += 1\n","            label_age = 0\n","        elif 12 <= age <= 23:\n","            num14_23 += 1\n","            label_age = 1\n","        elif 24 <= age <= 39:\n","            num24_39 += 1\n","            label_age = 2\n","        elif 40 <= age <= 55:\n","            num40_55 += 1\n","            label_age = 3\n","        else:\n","            num56_80 += 1\n","            label_age = 4\n","\n","        label_gender = int(gender)\n","        if label_gender == 3:\n","            label_gender = 1\n","        if label_gender == 0:\n","            male += 1\n","        else:\n","            female += 1\n","\n","        label_gender = int(gender)\n","        if label_gender == 3:\n","            label_gender = 1\n","            \n","        label_race=int(race)\n","        if label_race==0:\n","            White=White+1\n","        if label_race==1:\n","            Black+=1\n","        if label_race==2:\n","            Asian+=1\n","        if label_race==3:\n","            Indian+=1\n","        if label_race==4:\n","            Others+=1\n","                 \n","        img = cv2.resize(img, (img_size, img_size), cv2.INTER_AREA)\n","        data.append((img, label_age, label_gender,label_race))\n","\n","    print('Number of data')\n","    print('1-13: ', num1_13)\n","    print('14-23: ', num14_23)\n","    print('24-39: ', num24_39)\n","    print('40-55: ', num40_55)\n","    print('56-80: ', num56_80)\n","    print('male: ', male)\n","    print('female: ', female)\n","    print('White: ', White)\n","    print('Black: ', Black)\n","    print('Asian: ', Asian)\n","    print('Indian: ', Indian)\n","    print('Others: ', Others)\n","    \n","    with open('data_5_ukt.npy','wb') as f:\n","        np.save(f, data)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-U8tUPtGhss","outputId":"0a83a18c-5649-4460-f37a-7a6bae075b5e"},"source":["create_5utk_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of data\n","1-13:  3283\n","14-23:  2761\n","24-39:  10429\n","40-55:  3858\n","56-80:  2834\n","male:  12208\n","female:  10957\n","White:  9698\n","Black:  4478\n","Asian:  3348\n","Indian:  3952\n","Others:  1689\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lvrCZXSKGhss"},"source":["### create 10 classes"]},{"cell_type":"code","metadata":{"id":"JE0JEoXMGhst"},"source":["def create_10utk_data():\n","    img_dir = Path('./UTKFace/')\n","    img_size = IMAGE_SIZE\n","    num1_8 = 0\n","    num9_16 = 0\n","    num17_24 = 0\n","    num25_32 = 0\n","    num33_40 = 0\n","    num41_48 = 0\n","    num49_56 = 0\n","    num57_64 = 0\n","    num65_72 = 0\n","    num73_80 = 0\n","    male = 0\n","    female = 0\n","    White=0\n","    Black=0\n","    Asian=0\n","    Indian=0\n","    Others=0\n","    \n","    data = []\n","    for img_path in img_dir.glob('*.jpg'):\n","        name = img_path.name    # [age]_[gender]_[race]_[date&time].jpg\n","        age, gender,race = name.split('_')[:3]\n","        img = cv2.imread(str(img_path))\n","        \n","        age = int(age)\n","    \n","        if 1 <= age <= 8:\n","            num1_8 += 1\n","            label_age = 0\n","        elif 9 <= age <= 16:\n","            num9_16 += 1\n","            label_age = 1\n","        elif 17 <= age <= 24:\n","            num17_24 += 1\n","            label_age = 2\n","        elif 25 <= age <= 32:\n","            num25_32 += 1\n","            label_age = 3\n","        elif 33 <= age <= 40:\n","            num33_40 += 1\n","            label_age = 4\n","        elif 41 <= age <= 48:\n","            num41_48 += 1\n","            label_age = 5\n","        elif 49 <= age <= 56:\n","            num49_56 += 1\n","            label_age = 6  \n","        elif 57 <= age <= 64:\n","            num57_64 += 1\n","            label_age = 7   \n","        elif 65 <= age <= 72:\n","            num65_72 += 1\n","            label_age = 8      \n","        else:\n","            num73_80 += 1\n","            label_age = 9\n","\n","        label_gender = int(gender)\n","        if label_gender == 3:\n","            label_gender = 1\n","        if label_gender == 0:\n","            male += 1\n","        else:\n","            female += 1\n","\n","        label_gender = int(gender)\n","        if label_gender == 3:\n","            label_gender = 1\n","            \n","        label_race=int(race)\n","        if label_race==0:\n","            White=White+1\n","        if label_race==1:\n","            Black+=1\n","        if label_race==2:\n","            Asian+=1\n","        if label_race==3:\n","            Indian+=1\n","        if label_race==4:\n","            Others+=1\n","                 \n","        img = cv2.resize(img, (img_size, img_size), cv2.INTER_AREA)\n","        data.append((img, label_age, label_gender,label_race))\n","\n","    print('Number of data')\n","    print('1_8: ', num1_8)\n","    print('9_16: ', num9_16)\n","    print('17_24: ', num17_24)\n","    print('25_32: ', num25_32)\n","    print('33_40: ', num33_40)\n","    print('41_48: ', num41_48)\n","    print('49_56: ', num49_56)\n","    print('57_64: ', num57_64)\n","    print('65_72: ', num65_72)\n","    print('73_80: ', num73_80)\n","    print('male: ', male)\n","    print('female: ', female)\n","    print('White: ', White)\n","    print('Black: ', Black)\n","    print('Asian: ', Asian)\n","    print('Indian: ', Indian)\n","    print('Others: ', Others)\n","    \n","    with open('data_10_ukt.npy','wb') as f:\n","        np.save(f, data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1v1YTA5YGhsu","outputId":"186bd7ba-0123-4e2a-e9ff-23146de1cc68"},"source":["create_10utk_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of data\n","1_8:  2896\n","9_16:  1179\n","17_24:  2828\n","25_32:  6772\n","33_40:  3324\n","41_48:  1571\n","49_56:  1997\n","57_64:  1180\n","65_72:  864\n","73_80:  1094\n","male:  12391\n","female:  11314\n","White:  10078\n","Black:  4526\n","Asian:  3434\n","Indian:  3975\n","Others:  1692\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1HlB9NpXGhsu"},"source":[""],"execution_count":null,"outputs":[]}]}
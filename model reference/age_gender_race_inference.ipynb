{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"age_gender_race_inference.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1AGabwCjJQt-4Mpl_hVOqA8RIOtishjMC","authorship_tag":"ABX9TyPZdqrHep83DLQt+1821JGl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3_nqdecRZP4z"},"source":["!pip install git+https://github.com/qubvel/segmentation_models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8GDxHbrBZp5T"},"source":["from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n","from keras import optimizers\n","from keras.utils.generic_utils import get_custom_objects\n","from keras.layers import GlobalMaxPool2D, Dropout, Dense, Activation, BatchNormalization\n","from keras.models import Model\n","import numpy as np\n","from keras.backend import sigmoid\n","from efficientnet.keras import EfficientNetB4 as NetB4\n","from efficientnet.keras import EfficientNetB4 as NetB5\n","from efficientnet.keras import EfficientNetB4 as NetB6\n","from efficientnet.keras import EfficientNetB4 as NetB7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6UpO0dQY3j1"},"source":["import cv2\n","import numpy as np\n","import os\n","import argparse\n","import keras\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import time\n","from mtcnn import MTCNN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Shv26F0BJzDc"},"source":["pip install mtcnn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rB18fg3PACP7"},"source":["## set parameters"]},{"cell_type":"code","metadata":{"id":"mOidclELy-lJ"},"source":["IMAGE_SIZE = 56\n","BATCH_SIZE = 256\n","WEIGHT_INIT = 0.08\n","NUM_AGE_CLASSES = 3\n","NUM_GENDER_CLASSES = 2\n","DROPOUT_RATE = 0.2\n","input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n","NUM_EPOCHS = 40\n","DECAY_LR_RATE = 0.9\n","NUM_AGE_CLASSES=3\n","min_score = 1.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QGlYAwxityM1"},"source":["## lode the data"]},{"cell_type":"code","metadata":{"id":"PK0c8sR0djvy"},"source":["import keras\n","import os\n","import numpy as np\n","\n","class Datasets(object):\n","    def __init__(self,data_name):\n","        self.data_name=data_name\n","        self.datasets = self.getData(self)\n","        self.final_data = []\n","        self.convert_data_format()\n","\n","\n","    def gen(self):\n","        # np.random.shuffle(self.final_data)\n","\n","        images = []\n","        age_labels = []\n","        gender_labels = []\n","        race_labels=[]\n","\n","        for i in range(len(self.final_data)):\n","            image, age, gender,race = self.final_data[i]\n","            images.append(image)\n","            age_labels.append(age)\n","            gender_labels.append(gender)\n","            race_labels.append(race)\n","    \n","        age_labels = keras.utils.to_categorical(age_labels, num_classes=NUM_AGE_CLASSES)\n","        gender_labels = keras.utils.to_categorical(gender_labels, num_classes=2)\n","        race_labels = keras.utils.to_categorical(race_labels, num_classes=5)\n","\n","        return images, age_labels, gender_labels, race_labels\n","\n","    @staticmethod\n","    def getData(self):\n","        print('Loading age image...')\n","        # data_3\n","        if self.data_name=='data_3_utk':\n","          data = np.load(os.path.join(os.getcwd(), '/content/drive/MyDrive/3033proj/data_3_utk.npy'), allow_pickle=True) \n","        if self.data_name=='data_5_utk':\n","          data = np.load(os.path.join(os.getcwd(), '/content/drive/MyDrive/3033proj/data_5_utk.npy'), allow_pickle=True) \n","        if self.data_name=='data_10_utk':\n","          data = np.load(os.path.join(os.getcwd(), '/content/drive/MyDrive/3033proj/data_10_utk.npy'), allow_pickle=True)\n","        np.random.shuffle(data)\n","        all_data = []\n","        # random select 20000 data\n","        for i in range(20000):  ### number of samples\n","            all_data.append(data[i])\n","        print('Number of age data:', str(len(all_data)))\n","        return all_data\n","\n","    def convert_data_format(self):\n","        # Age datasets:\n","        for i in range(len(self.datasets)):\n","            image = self.datasets[i][0] / 255.0\n","            age_labels = self.datasets[i][1]\n","            gender_labels = self.datasets[i][2]\n","            race_labels= self.datasets[i][3]\n","\n","            self.final_data.append((image, age_labels, gender_labels,race_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ukwH33bDAQ0D"},"source":["## model"]},{"cell_type":"code","metadata":{"id":"rOQvHyjadEio"},"source":["import pandas as pd\n","class SwishActivation(Activation):\n","    def __init__(self, activation, **kwargs):\n","        super(SwishActivation, self).__init__(activation, **kwargs)\n","        self.__name__ = 'swish_act'\n","\n","def swish_act(x, beta=1):\n","    return x * sigmoid(beta * x)\n","\n","class Efficient_Net(object):\n","    def __init__(self, model_name, data_name, trainable=True):\n","        self.trainable = trainable\n","        self.model_name=model_name\n","        self.data_name=data_name\n","        if self.trainable: \n","            self.train_data = Datasets(data_name=self.data_name)\n","        self.model = self.build_model(self.model_name)\n","\n","        # Compile the model\n","        losses = {\n","            \"age_output\": \"categorical_crossentropy\",\n","            \"gender_output\": \"categorical_crossentropy\",\n","             \"race_output\": \"categorical_crossentropy\"\n","\n","        }\n","\n","        opt = optimizers.Adam(1e-3)\n","        self.model.compile(loss=losses, optimizer=opt, metrics=['acc'])\n","\n","        # Train the part you added\n","        if self.trainable:\n","            self.model.summary()\n","\n","    @staticmethod\n","    def build_age_branch(x):\n","        # Output age branch\n","        predictions_age = Dense(NUM_AGE_CLASSES, activation=\"softmax\", name='age_output')(x)\n","\n","        return predictions_age\n","\n","    @staticmethod\n","    def build_gender_branch(x):\n","        # Output gender branch\n","        predictions_gender = Dense(2, activation=\"softmax\", name='gender_output')(x)\n","\n","        return predictions_gender\n","\n","\n","    def build_race_branch(self,x):\n","        # Output race branch\n","        predictions_race = Dense(5, activation=\"softmax\", name='race_output')(x)\n","\n","        return predictions_race\n","\n","    def build_model(self,model_name):\n","        get_custom_objects().update({'swish_act': SwishActivation(swish_act)})\n","\n","        # Model\n","        if model_name=='age_gender_race_B4':\n","          model = NetB4(weights='imagenet', include_top=False, input_shape=input_shape)\n","        if model_name=='age_gender_race_B5':\n","          model = NetB5(weights='imagenet', include_top=False, input_shape=input_shape)\n","        if model_name=='age_gender_race_B6':\n","          model = NetB6(weights='imagenet', include_top=False, input_shape=input_shape)\n","        if model_name=='age_gender_race_B7':\n","          model = NetB7(weights='imagenet', include_top=False, input_shape=input_shape)\n","        \n","\n","        # Adding 2 fully-connected layers to B4.\n","        x = model.output\n","        x = BatchNormalization()(x)\n","        x = GlobalMaxPool2D(name='gap1')(x)\n","        x = Dropout(DROPOUT_RATE, name='dropout1')(x)\n","\n","        # Output layer\n","        predictions_age = self.build_age_branch(x)\n","        predictions_gender = self.build_gender_branch(x)\n","        predictions_race = self.build_race_branch(x)\n","        model_final = Model(inputs=model.input, outputs=[predictions_age, predictions_gender,predictions_race])\n","\n","        return model_final\n","\n","    def train(self):\n","        # reduce learning rate\n","        reduce_lr = ReduceLROnPlateau(monitor='val_age_output_acc', factor=DECAY_LR_RATE, patience=5, verbose=1, )\n","        # Model Checkpoint\n","        # cpt_save = ModelCheckpoint( '/content/drive/MyDrive/3033proj/weights/weight_{}.h5'.format(model_name+data_name), save_best_only=True, monitor='val_age_output_acc', mode='max')\n","        # print(\"Training......\")\n","        trainX, trainAgeY, trainGenderY ,trainRaceY= self.train_data.gen()\n","        trainX = np.array(trainX)\n","\n","\n","\n","        history=self.model.fit(trainX, {\"age_output\": trainAgeY, \"gender_output\": trainGenderY, \"race_output\": trainRaceY}, validation_split=0.2,\n","                       callbacks=reduce_lr, verbose=1, epochs=40, shuffle=True,\n","                       batch_size=256)\n","        \n","        dir ='/content/drive/MyDrive/3033proj/model_log/'\n","        log_path = dir+self.model_name+self.data_name+'_2log.csv'\n","        hist = pd.DataFrame(history.history)\n","        hist.to_csv(log_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yD4knmK3t7b-"},"source":["## inference"]},{"cell_type":"markdown","metadata":{"id":"rTg_E3HcJRqK"},"source":["### 'age_gender_race_B6', 'data_3_utk'"]},{"cell_type":"code","metadata":{"id":"Ukw7fqyyhjhU"},"source":["def draw_labels_and_boxes(img, boxes, result, margin):\n","    class_ids_age = np.argmax(result[0], axis=1)\n","    class_ids_gender = np.argmax(result[1], axis=1)\n","    class_ids_race = np.argmax(result[2], axis=1)\n","\n","    if len(class_ids_age) <= 0:\n","        print('No age predicted')\n","        return None\n","    if len(class_ids_gender) <= 0:\n","        print('No gender predicted')\n","        return None\n","    if len(class_ids_race) <= 0:\n","        print('No race predicted')\n","        return None\n","\n","    # Initialize color to perform each labels uniquely\n","    # colors = np.random.randint(0, 255, size=(num_age_label, 3), dtype='uint8')\n","\n","    for i in range(len(class_ids_age)):\n","        # get the bounding box coordinates\n","        left, top, right, bottom = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n","        width = right - left\n","        height = bottom - top\n","        img_h, img_w = img.shape[:2]\n","\n","        x1 = max(int(left - margin * width), 0)\n","        y1 = max(int(top - margin * height), 0)\n","        x2 = min(int(right + margin * width), img_w - 1)\n","        y2 = min(int(bottom + margin * height), img_h - 1)\n","        # Get the unique color for this class\n","        # color = [int(c) for c in colors[class_ids_age[i]]]\n","        # Color red\n","        color = (0, 0, 255)\n","\n","        # classify label according to result\n","\n","        if class_ids_age[i] == 0:\n","            age = '1-26'\n","        elif class_ids_age[i] == 1:\n","            age = '27-52'\n","        elif class_ids_age[i] == 2:\n","            age = '53-80'\n","    \n","\n","        if class_ids_gender[i] == 0:\n","            gender = 'Male'\n","        elif class_ids_gender[i] == 1:\n","            gender = 'Female'\n","\n","        if class_ids_race[i] == 0:\n","            race = 'White'\n","        elif class_ids_race[i] == 1:\n","            race = 'Black'\n","        elif class_ids_race[i] == 2:\n","            race = 'Asian'\n","        elif class_ids_race[i] == 3:\n","            race = 'Indian'\n","        elif class_ids_race[i] == 4:\n","            race = 'Others'\n","\n","        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n","        text = 'Gender: {}, Age: {}, \\nRace: {}'.format(gender, age,race)\n","        y0,dy=y1 - 15,10\n","        for i,txt in enumerate(text.split('\\n')):\n","          y = y0+i*dy\n","          cv2.putText(img, txt, (x1 - 5, y), cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n","    return img\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fLXBVCoKb-TW"},"source":["NUM_AGE_CLASSES = 3\n","weight_path = '/content/drive/MyDrive/3033proj/weights/weight_age_gender_race_B6data_3_utk.h5'\n","img_path='/content/drive/MyDrive/3033proj/elder1.jpeg'\n","\n","boxes = []\n","\n","# Detector use by MTCNN\n","detector = MTCNN()\n","\n","# Load image\n","image = cv2.imread(img_path)\n","img_h, img_w = image.shape[:2]\n","\n","# Load weights\n","model = Efficient_Net('age_gender_race_B4', 'data_3_utk', trainable=True).model\n","model.load_weights(weight_path)\n","\n","# Run detector through a image(frame)\n","start_time = time.time()\n","result = detector.detect_faces(image)\n","end_time = time.time()\n","\n","num_detected_face = len(result)\n","if num_detected_face == 0:\n","    print('No detected face')\n","    exit()\n","\n","faces = np.empty((num_detected_face, IMAGE_SIZE, IMAGE_SIZE, 3))\n","print(\"{}: detected {} faces on {}s\".format(img_path, num_detected_face, end_time - start_time))\n","\n","# crop faces\n","for i in range(len(result)):\n","    bounding_box = result[i]['box']\n","    keypoints = result[i]['keypoints']\n","\n","    # coordinates of boxes\n","    left, top = bounding_box[0], bounding_box[1]\n","    right, bottom = bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3]\n","\n","    # coordinates of cropped image\n","    x1_crop = max(int(left), 0)\n","    y1_crop = max(int(top), 0)\n","    x2_crop = int(right)\n","    y2_crop = int(bottom)\n","\n","    cropped_face = image[y1_crop:y2_crop, x1_crop:x2_crop, :]\n","    face = cv2.resize(cropped_face, (IMAGE_SIZE, IMAGE_SIZE))\n","    faces[i, :, :, :] = face\n","    box = (x1_crop, y1_crop, x2_crop, y2_crop)\n","    boxes.append(box)\n","\n","# predict\n","result = model.predict(faces / 255.0)\n","\n","# Draw bounding boxes and labels on image\n","image = draw_labels_and_boxes(image, boxes, result, 0.001)\n","\n","if image is None:\n","    exit()\n","\n","image = cv2.resize(image, (img_w, img_h), cv2.INTER_AREA)\n","cv2.imwrite('selenagomez.jpg', image)\n","# cv2.imshow('img', image)\n","cv2_imshow(image)\n","if cv2.waitKey(0) & 0xFF == ord('q'):\n","    exit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZtfxc3jKYYd"},"source":["### age_gender_race_B4', 'data_5_utk'"]},{"cell_type":"code","metadata":{"id":"rFMvXNSifcU2"},"source":["def draw_labels_and_boxes(img, boxes, result, margin):\n","    class_ids_age = np.argmax(result[0], axis=1)\n","    class_ids_gender = np.argmax(result[1], axis=1)\n","    class_ids_race = np.argmax(result[2], axis=1)\n","\n","    if len(class_ids_age) <= 0:\n","        print('No age predicted')\n","        return None\n","    if len(class_ids_gender) <= 0:\n","        print('No gender predicted')\n","        return None\n","    if len(class_ids_race) <= 0:\n","        print('No race predicted')\n","        return None\n","\n","    # Initialize color to perform each labels uniquely\n","    # colors = np.random.randint(0, 255, size=(num_age_label, 3), dtype='uint8')\n","\n","    for i in range(len(class_ids_age)):\n","        # get the bounding box coordinates\n","        left, top, right, bottom = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n","        width = right - left\n","        height = bottom - top\n","        img_h, img_w = img.shape[:2]\n","\n","        x1 = max(int(left - margin * width), 0)\n","        y1 = max(int(top - margin * height), 0)\n","        x2 = min(int(right + margin * width), img_w - 1)\n","        y2 = min(int(bottom + margin * height), img_h - 1)\n","        # Get the unique color for this class\n","        # color = [int(c) for c in colors[class_ids_age[i]]]\n","        # Color red\n","        color = (0, 0, 255)\n","\n","        # classify label according to result\n","        if class_ids_age[i] == 0:\n","            age = '1-26'\n","        elif class_ids_age[i] == 1:\n","            age = '27-52'\n","        elif class_ids_age[i] == 2:\n","            age = '53-80'\n","        elif class_ids_age[i] == 3:\n","            age = '40-55'\n","        elif class_ids_age[i] == 4:\n","            age = '56-80'\n","\n","\n","        if class_ids_gender[i] == 0:\n","            gender = 'Male'\n","        elif class_ids_gender[i] == 1:\n","            gender = 'Female'\n","\n","        if class_ids_race[i] == 0:\n","            race = 'White'\n","        elif class_ids_race[i] == 1:\n","            race = 'Black'\n","        elif class_ids_race[i] == 2:\n","            race = 'Asian'\n","        elif class_ids_race[i] == 3:\n","            race = 'Indian'\n","        elif class_ids_race[i] == 4:\n","            race = 'Others'\n","\n","        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n","        text = 'Gender: {}, Age: {}, \\nRace: {}'.format(gender, age,race)\n","        y0,dy=y1 - 15,10\n","        for i,txt in enumerate(text.split('\\n')):\n","          y = y0+i*dy\n","          cv2.putText(img, txt, (x1 - 5, y), cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n","    return img\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjro1trcjzRU"},"source":["NUM_AGE_CLASSES = 5\n","weight_path = '/content/drive/MyDrive/3033proj/weights/weight_age_gender_race_B4data_5_utk.h5'\n","img_path='/content/drive/MyDrive/3033proj/elder1.jpeg'\n","\n","boxes = []\n","\n","# Detector use by MTCNN\n","detector = MTCNN()\n","\n","# Load image\n","image = cv2.imread(img_path)\n","img_h, img_w = image.shape[:2]\n","\n","# Load weights\n","model = Efficient_Net('age_gender_race_B4', 'data_3_utk', trainable=True).model\n","model.load_weights(weight_path)\n","\n","# Run detector through a image(frame)\n","start_time = time.time()\n","result = detector.detect_faces(image)\n","end_time = time.time()\n","\n","num_detected_face = len(result)\n","if num_detected_face == 0:\n","    print('No detected face')\n","    exit()\n","\n","faces = np.empty((num_detected_face, IMAGE_SIZE, IMAGE_SIZE, 3))\n","print(\"{}: detected {} faces on {}s\".format(img_path, num_detected_face, end_time - start_time))\n","\n","# crop faces\n","for i in range(len(result)):\n","    bounding_box = result[i]['box']\n","    keypoints = result[i]['keypoints']\n","\n","    # coordinates of boxes\n","    left, top = bounding_box[0], bounding_box[1]\n","    right, bottom = bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3]\n","\n","    # coordinates of cropped image\n","    x1_crop = max(int(left), 0)\n","    y1_crop = max(int(top), 0)\n","    x2_crop = int(right)\n","    y2_crop = int(bottom)\n","\n","    cropped_face = image[y1_crop:y2_crop, x1_crop:x2_crop, :]\n","    face = cv2.resize(cropped_face, (IMAGE_SIZE, IMAGE_SIZE))\n","    faces[i, :, :, :] = face\n","    box = (x1_crop, y1_crop, x2_crop, y2_crop)\n","    boxes.append(box)\n","\n","# predict\n","result = model.predict(faces / 255.0)\n","\n","# Draw bounding boxes and labels on image\n","image = draw_labels_and_boxes(image, boxes, result, 0.001)\n","\n","if image is None:\n","    exit()\n","\n","image = cv2.resize(image, (img_w, img_h), cv2.INTER_AREA)\n","cv2.imwrite('selenagomez.jpg', image)\n","# cv2.imshow('img', image)\n","cv2_imshow(image)\n","if cv2.waitKey(0) & 0xFF == ord('q'):\n","    exit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lkAhoUdVWc12"},"source":["### age_gender_race_B4data_10_utk"]},{"cell_type":"code","metadata":{"id":"Q3klkiHzfeng"},"source":["def draw_labels_and_boxes(img, boxes, result, margin):\n","    class_ids_age = np.argmax(result[0], axis=1)\n","    class_ids_gender = np.argmax(result[1], axis=1)\n","    class_ids_race = np.argmax(result[2], axis=1)\n","\n","    if len(class_ids_age) <= 0:\n","        print('No age predicted')\n","        return None\n","    if len(class_ids_gender) <= 0:\n","        print('No gender predicted')\n","        return None\n","    if len(class_ids_race) <= 0:\n","        print('No race predicted')\n","        return None\n","\n","    # Initialize color to perform each labels uniquely\n","    # colors = np.random.randint(0, 255, size=(num_age_label, 3), dtype='uint8')\n","\n","    for i in range(len(class_ids_age)):\n","        # get the bounding box coordinates\n","        left, top, right, bottom = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n","        width = right - left\n","        height = bottom - top\n","        img_h, img_w = img.shape[:2]\n","\n","        x1 = max(int(left - margin * width), 0)\n","        y1 = max(int(top - margin * height), 0)\n","        x2 = min(int(right + margin * width), img_w - 1)\n","        y2 = min(int(bottom + margin * height), img_h - 1)\n"," \n","        color = (0, 0, 255)\n","\n","        # classify label according to result\n","\n","        if class_ids_age[i] == 0:\n","            age = '1-8'\n","        elif class_ids_age[i] == 1:\n","            age = '9-16'\n","        elif class_ids_age[i] == 2:\n","            age = '17-24'\n","        elif class_ids_age[i] == 3:\n","            age = '25-32'\n","        elif class_ids_age[i] == 4:\n","            age = '33-40'\n","        elif class_ids_age[i] == 5:\n","            age = '41-48'\n","        elif class_ids_age[i] == 6:\n","            age = '49-56'\n","        elif class_ids_age[i] == 7:\n","            age = '57-64'\n","        elif class_ids_age[i] == 8:\n","            age = '65-72'\n","        elif class_ids_age[i] == 9:\n","            age = '73-80'\n","\n","        if class_ids_gender[i] == 0:\n","            gender = 'Male'\n","        elif class_ids_gender[i] == 1:\n","            gender = 'Female'\n","\n","        if class_ids_race[i] == 0:\n","            race = 'White'\n","        elif class_ids_race[i] == 1:\n","            race = 'Black'\n","        elif class_ids_race[i] == 2:\n","            race = 'Asian'\n","        elif class_ids_race[i] == 3:\n","            race = 'Indian'\n","        elif class_ids_race[i] == 4:\n","            race = 'Others'\n","\n","        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n","        text = 'Gender: {}, Age: {}, \\nRace: {}'.format(gender, age,race)\n","        y0,dy=y1 - 15,10\n","        for i,txt in enumerate(text.split('\\n')):\n","          y = y0+i*dy\n","          cv2.putText(img, txt, (x1 - 5, y), cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n","    return img\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnPscDiDWf4t"},"source":["NUM_AGE_CLASSES = 10\n","weight_path = '/content/drive/MyDrive/3033proj/weights/weight_age_gender_race_B4data_10_utk.h5'\n","img_path='/content/drive/MyDrive/3033proj/elder1.jpeg'\n","\n","boxes = []\n","\n","# Detector use by MTCNN\n","detector = MTCNN()\n","\n","# Load image\n","image = cv2.imread(img_path)\n","img_h, img_w = image.shape[:2]\n","\n","# Load weights\n","model = Efficient_Net('age_gender_race_B4', 'data_3_utk', trainable=True).model\n","model.load_weights(weight_path)\n","\n","# Run detector through a image(frame)\n","start_time = time.time()\n","result = detector.detect_faces(image)\n","end_time = time.time()\n","\n","num_detected_face = len(result)\n","if num_detected_face == 0:\n","    print('No detected face')\n","    exit()\n","\n","faces = np.empty((num_detected_face, IMAGE_SIZE, IMAGE_SIZE, 3))\n","print(\"{}: detected {} faces on {}s\".format(img_path, num_detected_face, end_time - start_time))\n","\n","# crop faces\n","for i in range(len(result)):\n","    bounding_box = result[i]['box']\n","    keypoints = result[i]['keypoints']\n","\n","    # coordinates of boxes\n","    left, top = bounding_box[0], bounding_box[1]\n","    right, bottom = bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3]\n","\n","    # coordinates of cropped image\n","    x1_crop = max(int(left), 0)\n","    y1_crop = max(int(top), 0)\n","    x2_crop = int(right)\n","    y2_crop = int(bottom)\n","\n","    cropped_face = image[y1_crop:y2_crop, x1_crop:x2_crop, :]\n","    face = cv2.resize(cropped_face, (IMAGE_SIZE, IMAGE_SIZE))\n","    faces[i, :, :, :] = face\n","    box = (x1_crop, y1_crop, x2_crop, y2_crop)\n","    boxes.append(box)\n","\n","# predict\n","result = model.predict(faces / 255.0)\n","\n","# Draw bounding boxes and labels on image\n","image = draw_labels_and_boxes(image, boxes, result, 0.001)\n","\n","if image is None:\n","    exit()\n","\n","image = cv2.resize(image, (img_w, img_h), cv2.INTER_AREA)\n","cv2.imwrite('selenagomez.jpg', image)\n","# cv2.imshow('img', image)\n","cv2_imshow(image)\n","if cv2.waitKey(0) & 0xFF == ord('q'):\n","    exit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00SP1094eqSO"},"source":[""],"execution_count":null,"outputs":[]}]}